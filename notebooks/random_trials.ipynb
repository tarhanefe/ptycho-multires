{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efe/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/efe/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/.venv/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"..\")\n",
    "from src.cpwc.multires.class_multiressolver import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src.cpwc.tools.ptychography import Ptychography as Ptychography\n",
    "from src.cpwc.tools.utils import *\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set seeds \n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) and obj.is_cuda:\n",
    "            print(type(obj), obj.size())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "cycle = [0, -1, -1, -1,  1, 1, 1]\n",
    "lmbda = 0\n",
    "tol = [1e-10] * 9\n",
    "tol_in = [1e-10] * 9\n",
    "device = 'cuda'\n",
    "max_scale = 9\n",
    "max_probe_size = 128\n",
    "image = np.load(\"test_data/potential.npy\")\n",
    "image = (image - image.min())/(image.max() - image.min()) \n",
    "image_tensor = torch.tensor(image).double().to(device).view(1, 1, 2**max_scale, 2**max_scale)\n",
    "image_tensor_ = torch.exp(1j * image_tensor)\n",
    "multires = MultiRes(max_scale, device)\n",
    "\n",
    "\n",
    "def extract_data(nested_list):\n",
    "    result = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):  # If the item is a list, recurse into it\n",
    "            result.extend(extract_data(item))\n",
    "        else:  # If the item is not a list, add it to the result\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "def unwrap_2d(phase):\n",
    "    \"\"\"\n",
    "    Unwraps a 2D phase array using NumPy's 1D unwrap function.\n",
    "    \n",
    "    Parameters:\n",
    "    phase (numpy array): The 2D phase array to be unwrapped.\n",
    "    \n",
    "    Returns:\n",
    "    unwrapped_phase (numpy array): The 2D unwrapped phase array.\n",
    "    \"\"\"\n",
    "    # Unwrap along the first axis (rows)\n",
    "    unwrapped_phase = np.unwrap(phase, axis=0)\n",
    "    \n",
    "    # Unwrap along the second axis (columns)\n",
    "    unwrapped_phase = np.unwrap(unwrapped_phase, axis=1)\n",
    "    \n",
    "    return unwrapped_phase\n",
    "\n",
    "def save_data(model,model_name,image):\n",
    "    image = image[::,::]\n",
    "    mean_img = np.mean(image)\n",
    "    loss_data = extract_data(model.measures[\"loss\"])\n",
    "    cos_sim = extract_data(model.measures[\"csim\"])\n",
    "    phase = torch.angle(model.c_k[0,0,:,:].to('cpu'))\n",
    "    phase = phase.numpy()\n",
    "    phase = unwrap_2d(phase)\n",
    "    phase += (mean_img-np.mean(phase)) \n",
    "\n",
    "    np.save(\"np_data/{}_overlap_loss.npy\".format(model_name), loss_data)\n",
    "    np.save(\"np_data/{}_overlap_csim.npy\".format(model_name), cos_sim)\n",
    "    np.save(\"np_data/{}_overlap_image.npy\".format(model_name), phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_list = [i*10 for i in range(1,10)]\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "a = os.chdir(\"./dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- s = 9 -----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiResSolver' object has no attribute 'gt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m MultiResSolver(multires, loss, LR\u001b[38;5;241m=\u001b[39mLR, I_in\u001b[38;5;241m=\u001b[39mI_in, I_out\u001b[38;5;241m=\u001b[39mI_out, tol\u001b[38;5;241m=\u001b[39mtol, tol_in\u001b[38;5;241m=\u001b[39mtol_in, cycle\u001b[38;5;241m=\u001b[39mcycle, l1_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_row\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Solve\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_multigrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mprint_time()\n\u001b[1;32m     29\u001b[0m image \u001b[38;5;241m=\u001b[39m image[::,::]\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc/multires/class_multiressolver.py:154\u001b[0m, in \u001b[0;36mMultiResSolver.solve_multigrid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_k\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msols[s \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------- s = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(multires\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -----------\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_sols\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msols[s \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc/multires/class_multiressolver.py:111\u001b[0m, in \u001b[0;36mMultiResSolver.solve_scale\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m t_k, c_kp1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, d_k\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_measures()\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_kp1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m-\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miters\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcycle[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI_out\u001b[39m\u001b[38;5;124m\"\u001b[39m][g]:\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc/multires/class_multiressolver.py:86\u001b[0m, in \u001b[0;36mMultiResSolver.up_measures\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# self.measures[\"reg\"][-1].append(self.loss.calc_reg(x1,l1_type= self.l1_type))\u001b[39;00m\n\u001b[1;32m     85\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrel_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(calc_error(x2, x1, norm1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mcalc_loss))\n\u001b[0;32m---> 86\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsim\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcosine_similarity(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m, x1)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiResSolver' object has no attribute 'gt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "checkpoint_dir = \"gd/checkpoints25\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "seed = 0\n",
    "set_seed(seed)\n",
    "\n",
    "# Initialize probe and operator\n",
    "probe = Ptychography(image_tensor_, max_probe_size, max_probe_size, 1, device)\n",
    "LR = 1e-3\n",
    "max_shift = 96\n",
    "I_in = 15 * np.array([1, 15, 10, 5, 10, 30, 100])\n",
    "I_out = 10 * np.array([0, 0, 0, 0, 0, 0, 350])\n",
    "linOperator = Ptychography(max_scale=max_scale, max_probe_size=max_probe_size, max_shift=max_shift, device=device)\n",
    "image_tensor_ = linOperator.apply(image_tensor_)\n",
    "\n",
    "# Define loss function\n",
    "loss = Loss(linOperator, image_tensor_)\n",
    "\n",
    "# Initialize solver\n",
    "model = MultiResSolver(multires, loss, LR=LR, I_in=I_in, I_out=I_out, tol=tol, tol_in=tol_in, cycle=cycle, l1_type=\"l1_row\",gt=image)\n",
    "\n",
    "# Solve\n",
    "model.solve_multigrid()\n",
    "model.print_time()\n",
    "\n",
    "image = image[::,::]\n",
    "mean_img = np.mean(image)\n",
    "loss_data = extract_data(model.measures[\"loss\"])\n",
    "cos_sim = extract_data(model.measures[\"csim\"])\n",
    "phase = torch.angle(model.c_k[0,0,:,:].to('cpu'))\n",
    "phase = phase.numpy()\n",
    "phase = unwrap_2d(phase)\n",
    "phase += (mean_img-np.mean(phase)) \n",
    "# Extract and store new loss values\n",
    "# Save checkpoint and loss values\n",
    "np.save(checkpoint_dir+\"/overlap_loss_{}.npy\".format(seed), loss_data)\n",
    "np.save(checkpoint_dir+\"/overlap_csim_{}.npy\".format(seed), cos_sim)\n",
    "np.save(checkpoint_dir+\"/overlap_image_{}.npy\".format(seed), phase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the means and variances of the loss\n",
    "\n",
    "loss1 = np.load(\"./gd/checkpoints25/overlap_loss_0.npy\")\n",
    "loss2 = np.load(\"./gd/checkpoints25/overlap_loss_10.npy\")\n",
    "loss3 = np.load(\"./checkpoints25/overlap_loss_20.npy\")\n",
    "loss4 = np.load(\"./checkpoints25/overlap_loss_30.npy\")\n",
    "loss5 = np.load(\"./checkpoints25/overlap_loss_40.npy\")\n",
    "loss6 = np.load(\"./checkpoints25/overlap_loss_50.npy\")\n",
    "loss7 = np.load(\"./checkpoints25/overlap_loss_60.npy\")\n",
    "\n",
    "#Find the mean and variance of the 7 different loss values\n",
    "mean = (loss1 + loss2 + loss3 + loss4 + loss5 + loss6 + loss7)/7\n",
    "std = np.std(np.array([loss1, loss2, loss3, loss4, loss5, loss6, loss7]), axis=0)\n",
    "\n",
    "#Save mean and std\n",
    "np.save(\"./checkpoints25/mean_loss.npy\", mean)\n",
    "np.save(\"./checkpoints25/std_loss.npy\", std)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all\n",
    "\n",
    "mean75 = np.load(\"./checkpoints75/mean_loss.npy\")\n",
    "std75 = np.load(\"./checkpoints75/std_loss.npy\")\n",
    "\n",
    "mean50 = np.load(\"./checkpoints50/mean_loss.npy\")\n",
    "std50 = np.load(\"./checkpoints50/std_loss.npy\")\n",
    "\n",
    "mean25 = np.load(\"./checkpoints25/mean_loss.npy\")\n",
    "std25 = np.load(\"./checkpoints25/std_loss.npy\")\n",
    "\n",
    "plt.figure(figsize = (10, 5),dpi = 300)\n",
    "plt.semilogy(mean75, label=\"MRGD w/ 0.75 Overlap\")\n",
    "plt.fill_between(np.arange(len(mean75)), mean75-std75, mean75+std75, alpha=0.3)\n",
    "plt.semilogy(mean50, label=\"MRGD w/ 0.5 Overlap\")\n",
    "plt.fill_between(np.arange(len(mean50)), mean50-std50, mean50+std50, alpha=0.3)\n",
    "plt.semilogy(mean25, label=\"MRGD w/ 0.25 Overlap\")\n",
    "plt.fill_between(np.arange(len(mean25)), mean25-std25, mean25+std25, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
