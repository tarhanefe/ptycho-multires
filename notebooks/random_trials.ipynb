{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efe/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/efe/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/.venv/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"..\")\n",
    "from src.cpwc.multires.class_multiressolver import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src.cpwc.tools.ptychography import Ptychography as Ptychography\n",
    "from src.cpwc.tools.utils import *\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set seeds \n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) and obj.is_cuda:\n",
    "            print(type(obj), obj.size())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "cycle = [0, -1, -1, -1,  1, 1, 1]\n",
    "lmbda = 0\n",
    "tol = [1e-10] * 9\n",
    "tol_in = [1e-10] * 9\n",
    "device = 'cuda'\n",
    "max_scale = 9\n",
    "max_probe_size = 128\n",
    "image = np.load(\"test_data/potential.npy\")\n",
    "image = (image - image.min())/(image.max() - image.min()) \n",
    "image_tensor = torch.tensor(image).double().to(device).view(1, 1, 2**max_scale, 2**max_scale)\n",
    "image_tensor_ = torch.exp(1j * image_tensor)\n",
    "multires = MultiRes(max_scale, device)\n",
    "\n",
    "\n",
    "def extract_data(nested_list):\n",
    "    result = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):  # If the item is a list, recurse into it\n",
    "            result.extend(extract_data(item))\n",
    "        else:  # If the item is not a list, add it to the result\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "def unwrap_2d(phase):\n",
    "    \"\"\"\n",
    "    Unwraps a 2D phase array using NumPy's 1D unwrap function.\n",
    "    \n",
    "    Parameters:\n",
    "    phase (numpy array): The 2D phase array to be unwrapped.\n",
    "    \n",
    "    Returns:\n",
    "    unwrapped_phase (numpy array): The 2D unwrapped phase array.\n",
    "    \"\"\"\n",
    "    # Unwrap along the first axis (rows)\n",
    "    unwrapped_phase = np.unwrap(phase, axis=0)\n",
    "    \n",
    "    # Unwrap along the second axis (columns)\n",
    "    unwrapped_phase = np.unwrap(unwrapped_phase, axis=1)\n",
    "    \n",
    "    return unwrapped_phase\n",
    "\n",
    "def save_data(model,model_name,image):\n",
    "    image = image[::,::]\n",
    "    mean_img = np.mean(image)\n",
    "    loss_data = extract_data(model.measures[\"loss\"])\n",
    "    cos_sim = extract_data(model.measures[\"csim\"])\n",
    "    phase = torch.angle(model.c_k[0,0,:,:].to('cpu'))\n",
    "    phase = phase.numpy()\n",
    "    phase = unwrap_2d(phase)\n",
    "    phase += (mean_img-np.mean(phase)) \n",
    "\n",
    "    np.save(\"np_data/{}_overlap_loss.npy\".format(model_name), loss_data)\n",
    "    np.save(\"np_data/{}_overlap_csim.npy\".format(model_name), cos_sim)\n",
    "    np.save(\"np_data/{}_overlap_image.npy\".format(model_name), phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_list = [i*10 for i in range(10)]\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "a = os.chdir(\"./dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filenames)):\n",
    "    if filenames[i] not in os.listdir(\"./\"):\n",
    "        set_seed(seed_list[i]) \n",
    "        probe = Ptychography(image_tensor_, max_probe_size, max_probe_size, 1, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-2\n",
    "max_shift = 32\n",
    "I_in = 15*np.array([1, 15, 10, 5, 10, 30, 100])\n",
    "I_out = 10*np.array([0, 0, 0, 30, 10,10,300])\n",
    "linOperator = Ptychography(max_scale = max_scale,max_probe_size = max_probe_size ,max_shift = max_shift,device=device)\n",
    "image_tensor_ = linOperator.apply(image_tensor_)\n",
    "loss = Loss(linOperator,image_tensor_)\n",
    "model75 = MultiResSolver(multires, loss, LR = LR,\n",
    "                        I_in = I_in,\n",
    "                        I_out = I_out,\n",
    "                        tol = tol,\n",
    "                        tol_in = tol_in,\n",
    "                        cycle = cycle,\n",
    "                        l1_type = \"l1_row\",\n",
    "                        gt = image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
