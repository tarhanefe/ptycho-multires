{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93788563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efe/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "from src.cpwc.multires.class_multiressolver import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src.cpwc.tools.ptychography import Ptychography as Ptychography\n",
    "from src.cpwc.tools.utils import *\n",
    "torch.cuda.empty_cache()\n",
    "from src.utils.cuda_pyth import empty_cuda, print_cuda_tensors\n",
    "from src.utils.get_image import get_image\n",
    "from src.utils.noise import add_gaussian_noise, add_poisson_noise\n",
    "from src.utils.metrics import get_ring_average, F2fluxconverter\n",
    "from src.utils.manage_data import save_data,unwrap_2d,extract_data\n",
    "# Set seeds \n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "max_scale = 9\n",
    "image,image_tensor_ = get_image(\"samples/potential.npy\", max_scale,device)\n",
    "max_probe_size = 128\n",
    "cycle = [0, -1, -1, -1,  1, 1, 1]\n",
    "tol = [1e-10] * 9\n",
    "tol_in = [1e-15] * 9\n",
    "max_shift = 96\n",
    "lmbda = 1e-30\n",
    "#noise = 1e30\n",
    "linOperator = Ptychography(max_scale = max_scale,max_probe_size = max_probe_size ,max_shift = max_shift,device=device)\n",
    "multires = MultiRes(max_scale, device)\n",
    "image_tensor__ = linOperator.apply(image_tensor_)\n",
    "#image_tensor__ = add_poisson_noise(image_tensor__, noise, 'cuda')\n",
    "loss = Loss(linOperator,image_tensor__,lmbda= lmbda)\n",
    "I_in = 25*np.array([1, 15, 10, 5, 10, 30, 100])\n",
    "#I_out = 10*np.array([0, 0, 0, 30, 10,10,300])\n",
    "I_out = 10*np.array([0, 0, 0, 3, 1,1,117])\n",
    "#I_out = 10*np.array([0, 0, 0, 0, 0,0,122])\n",
    "\n",
    "LR_list = [0,0,0,2e-2,3e-2,5e-2,1e-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "cuda_tensors = []\n",
    "for obj in gc.get_objects():\n",
    "    if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "        cuda_tensors.append(obj)\n",
    "\n",
    "print(f\"Found {len(cuda_tensors)} CUDA tensors:\")\n",
    "for t in cuda_tensors:\n",
    "    print(f\"  • shape={tuple(t.shape)}, dtype={t.dtype}, bytes={t.element_size()*t.numel():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# how much your tensors are _actually_ holding\n",
    "print(\"allocated:\", torch.cuda.memory_allocated()/2**30, \"GiB\")\n",
    "\n",
    "# how much the allocator has reserved from the driver\n",
    "print(\"reserved: \", torch.cuda.memory_reserved() /2**30, \"GiB\")\n",
    "\n",
    "# a detailed breakdown\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12967d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pty = Ptychography(device='cuda')\n",
    "# ... after loading your ground truth/object and computing itilde ...\n",
    "o0 = torch.randn_like(image_tensor__, dtype=torch.complex64, device=device)\n",
    "L0 = linOperator.estimate_lipschitz(o0, image_tensor__)\n",
    "print(f\"Estimated L = {L0:.3e}, suggested lr = {1.0/L0:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b104ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 CUDA tensors:\n",
      "  • shape=(1, 1, 512, 512), dtype=torch.complex128, bytes=4,194,304\n",
      "  • shape=(512, 512), dtype=torch.complex64, bytes=2,097,152\n",
      "  • shape=(512, 512), dtype=torch.complex64, bytes=2,097,152\n",
      "  • shape=(1, 361, 512, 512), dtype=torch.float64, bytes=757,071,872\n",
      "  • shape=(1, 1, 2, 1), dtype=torch.float64, bytes=16\n",
      "  • shape=(1, 1, 1, 2), dtype=torch.float64, bytes=16\n",
      "  • shape=(1, 361, 512, 512), dtype=torch.complex64, bytes=757,071,872\n",
      "  • shape=(1, 1, 2, 2), dtype=torch.float64, bytes=32\n",
      "  • shape=(1, 361, 512, 512), dtype=torch.complex64, bytes=757,071,872\n",
      "  • shape=(1, 361, 512, 512), dtype=torch.complex64, bytes=757,071,872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efe/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/.venv/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:181: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "\n",
    "cuda_tensors = []\n",
    "for obj in gc.get_objects():\n",
    "    if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "        cuda_tensors.append(obj)\n",
    "\n",
    "print(f\"Found {len(cuda_tensors)} CUDA tensors:\")\n",
    "for t in cuda_tensors:\n",
    "    print(f\"  • shape={tuple(t.shape)}, dtype={t.dtype}, bytes={t.element_size()*t.numel():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cc846b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 722.00 MiB (GPU 0; 23.66 GiB total capacity; 21.87 GiB already allocated; 663.38 MiB free; 21.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(image_tensor__, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcomplex64, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m((linOperator\u001b[38;5;241m.\u001b[39mprobe\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[43mlinOperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_linop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m) \u001b[38;5;241m-\u001b[39m image_tensor__)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc/tools/ptychography.py:225\u001b[0m, in \u001b[0;36mPtychography.apply_linop\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized) \u001b[38;5;129;01mor\u001b[39;00m (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_shape):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m--> 225\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_linop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_scale:\n\u001b[1;32m    227\u001b[0m     out \u001b[38;5;241m=\u001b[39m LinOpFFTShift2D()\u001b[38;5;241m.\u001b[39mapply(out)\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc_v/tools/phaseretrieval.py:14\u001b[0m, in \u001b[0;36mPhaseRetrievalBase.apply_linop\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_linop\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc_v/tools/linop.py:225\u001b[0m, in \u001b[0;36mLinOpCat.apply\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlinop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlinop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinOpList\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc_v/tools/linop.py:225\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mtuple\u001b[39m(\u001b[43mlinop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m linop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLinOpList), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc_v/tools/linop_base.py:72\u001b[0m, in \u001b[0;36mLinOpComposition.apply\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinOp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinOp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc_v/tools/linop_base.py:72\u001b[0m, in \u001b[0;36mLinOpComposition.apply\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinOp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinOp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Multiresolution-Framework-for-Fourier-Ptychography/src/cpwc_v/tools/linop.py:110\u001b[0m, in \u001b[0;36mLinOpFFT2.apply\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mortho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 722.00 MiB (GPU 0; 23.66 GiB total capacity; 21.87 GiB already allocated; 663.38 MiB free; 21.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "o = torch.randn_like(image_tensor__, dtype=torch.complex64, device=device)\n",
    "2.0 * float((linOperator.probe.abs()**2).max()) * float((2*(linOperator.apply_linop(o).abs()**2).clamp(min=1e-8) - image_tensor__).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
